# Modern Lakehouse: DuckDB + Apache Iceberg + MinIO + dbt

LaboratÃ³rio prÃ¡tico de um **Lakehouse moderno** totalmente containerizado, demonstrando conceitos avanÃ§ados de engenharia de dados como versionamento, time travel, schema evolution e transformaÃ§Ãµes com dbt.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Conceitos](#conceitos)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o e Uso](#instalaÃ§Ã£o-e-uso)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Funcionalidades](#funcionalidades)
- [Acessando os ServiÃ§os](#acessando-os-serviÃ§os)
- [Exemplos de Uso](#exemplos-de-uso)
- [ComparaÃ§Ã£o com Databricks](#comparaÃ§Ã£o-com-databricks)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **Lakehouse** completo em ambiente local usando:

- **DuckDB**: Engine analÃ­tico in-memory otimizado para OLAP
- **Apache Iceberg**: Tabela format para versionamento e time travel
- **MinIO**: Storage S3-compatible para simular cloud storage
- **dbt**: Ferramenta de transformaÃ§Ã£o de dados (ELT)
- **Docker Compose**: OrquestraÃ§Ã£o de todos os serviÃ§os

### O que Ã© um Lakehouse?

Um **Lakehouse** combina as melhores caracterÃ­sticas de um **Data Lake** (armazenamento barato, formatos abertos) com as de um **Data Warehouse** (ACID transactions, schema enforcement, performance).

**Vantagens:**
- âœ… Armazenamento econÃ´mico (formato Parquet/Delta/Iceberg)
- âœ… Suporte a dados estruturados, semi-estruturados e nÃ£o estruturados
- âœ… ACID transactions e versionamento
- âœ… Time travel (acessar versÃµes anteriores dos dados)
- âœ… Schema evolution (evoluir schema sem quebrar compatibilidade)
- âœ… Performance de queries analÃ­ticas
- âœ… IntegraÃ§Ã£o com ferramentas modernas (Spark, dbt, etc)

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Docker Compose                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    MinIO     â”‚      â”‚    DuckDB    â”‚      â”‚     dbt      â”‚  â”‚
â”‚  â”‚  (S3 Local)  â”‚â—„â”€â”€â”€â”€â”€â”¤  (Analytics) â”‚â—„â”€â”€â”€â”€â”€â”¤ (Transform)  â”‚  â”‚
â”‚  â”‚  Port: 9000  â”‚      â”‚              â”‚      â”‚              â”‚  â”‚
â”‚  â”‚  Port: 9001  â”‚      â”‚              â”‚      â”‚              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â–²                    â–²                                   â”‚
â”‚         â”‚                    â”‚                                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚              Iceberg Tables                                       â”‚
â”‚         (s3://lakehouse/iceberg/)                                â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Init Service (One-time)                     â”‚   â”‚
â”‚  â”‚  â€¢ Cria bucket                                           â”‚   â”‚
â”‚  â”‚  â€¢ Gera dados fake                                       â”‚   â”‚
â”‚  â”‚  â€¢ Cria tabela Iceberg                                   â”‚   â”‚
â”‚  â”‚  â€¢ Insere dados                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **InicializaÃ§Ã£o**: O serviÃ§o `init` cria o bucket no MinIO, gera dados fake e cria a tabela Iceberg
2. **Armazenamento**: Dados sÃ£o armazenados no MinIO (S3-compatible) em formato Iceberg
3. **AnÃ¡lise**: DuckDB consulta diretamente as tabelas Iceberg no MinIO
4. **TransformaÃ§Ã£o**: dbt transforma os dados brutos em modelos analÃ­ticos (marts)

## ğŸ“š Conceitos

### Apache Iceberg

**Apache Iceberg** Ã© uma especificaÃ§Ã£o de tabela aberta para analytics em data lakes. Ele fornece:

- **ACID Transactions**: Garante consistÃªncia dos dados
- **Time Travel**: Acesse versÃµes anteriores dos dados
- **Schema Evolution**: Adicione/remova colunas sem quebrar queries antigas
- **Hidden Partitioning**: Particionamento automÃ¡tico e otimizado
- **Metadata Management**: Metadados versionados e eficientes

**Exemplo de Time Travel:**
```sql
-- Ver dados de 1 hora atrÃ¡s
SELECT * FROM vendas_iceberg 
FOR TIMESTAMP AS OF '2024-01-01 10:00:00';

-- Ver snapshot especÃ­fico
SELECT * FROM vendas_iceberg 
FOR VERSION AS OF 5;
```

**Exemplo de Schema Evolution:**
```sql
-- Adicionar nova coluna sem quebrar queries antigas
ALTER TABLE vendas_iceberg 
ADD COLUMN novo_campo VARCHAR;
```

### DuckDB

**DuckDB** Ã© um banco de dados analÃ­tico in-memory otimizado para OLAP (Online Analytical Processing). CaracterÃ­sticas:

- âš¡ Performance excepcional para queries analÃ­ticas
- ğŸ”Œ IntegraÃ§Ã£o nativa com Parquet, CSV, JSON
- ğŸ“¦ ExtensÃµes para S3, Iceberg, Postgres, etc
- ğŸ IntegraÃ§Ã£o Python/R fÃ¡cil
- ğŸ’¾ Zero configuraÃ§Ã£o

### MinIO

**MinIO** Ã© um servidor de armazenamento de objetos S3-compatible. Usado aqui para simular cloud storage localmente.

## ğŸš€ PrÃ©-requisitos

- **Docker** (versÃ£o 20.10+)
- **Docker Compose** (versÃ£o 2.0+)
- **Git** (para clonar o repositÃ³rio)

## ğŸ“¦ InstalaÃ§Ã£o e Uso

### 1. Clone o repositÃ³rio

```bash
git clone <repo-url>
cd modern-lakehouse-duckdb-iceberg
```

### 2. Inicie os serviÃ§os

```bash
docker compose up -d
```

Este comando irÃ¡:
- âœ… Baixar as imagens necessÃ¡rias
- âœ… Criar os containers
- âœ… Configurar volumes persistentes
- âœ… Executar o serviÃ§o de inicializaÃ§Ã£o automaticamente

### 3. Verifique os logs

```bash
# Ver logs de todos os serviÃ§os
docker compose logs -f

# Ver logs de um serviÃ§o especÃ­fico
docker compose logs -f init
```

### 4. Aguarde a inicializaÃ§Ã£o

O serviÃ§o `init` irÃ¡:
1. Aguardar MinIO estar disponÃ­vel
2. Criar o bucket `lakehouse`
3. Gerar 5.000 registros de vendas fake
4. Criar tabela Iceberg `vendas_iceberg`
5. Inserir os dados na tabela

**Tempo estimado**: 1-2 minutos

## ğŸ“ Estrutura do Projeto

```
modern-lakehouse-duckdb-iceberg/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ duckdb/
â”‚   â”‚   â””â”€â”€ Dockerfile          # Imagem DuckDB + Python
â”‚   â”œâ”€â”€ dbt/
â”‚   â”‚   â””â”€â”€ Dockerfile          # Imagem dbt + DuckDB adapter
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ Dockerfile          # Imagem de inicializaÃ§Ã£o
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/            # Modelos de staging (limpeza)
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_vendas.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â””â”€â”€ marts/              # Modelos analÃ­ticos
â”‚   â”‚       â”œâ”€â”€ fct_vendas.sql
â”‚   â”‚       â”œâ”€â”€ dim_produtos.sql
â”‚   â”‚       â”œâ”€â”€ dim_clientes.sql
â”‚   â”‚       â”œâ”€â”€ mart_vendas_mensal.sql
â”‚   â”‚       â””â”€â”€ schema.yml
â”‚   â”œâ”€â”€ dbt_project.yml         # ConfiguraÃ§Ã£o do projeto
â”‚   â””â”€â”€ profiles.yml            # Perfil de conexÃ£o
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_fake_data.py   # Gera dados fake
â”‚   â”œâ”€â”€ create_iceberg_table.py # Cria tabela Iceberg
â”‚   â”œâ”€â”€ example_queries.py      # Queries de exemplo
â”‚   â””â”€â”€ init_lakehouse.py       # Script de inicializaÃ§Ã£o
â”œâ”€â”€ data/                       # Dados gerados (volumes)
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos serviÃ§os
â””â”€â”€ README.md                   # Este arquivo
```

## âš™ï¸ Funcionalidades

### âœ… Funcionalidades Implementadas

1. **CriaÃ§Ã£o AutomÃ¡tica de Bucket**
   - Bucket `lakehouse` criado automaticamente no MinIO

2. **GeraÃ§Ã£o de Dados Fake**
   - 5.000 registros de vendas simulados
   - Dados realistas com produtos, clientes, descontos, etc

3. **Tabela Iceberg**
   - Tabela `vendas_iceberg` com particionamento por ano/mÃªs
   - Armazenada no MinIO em formato Iceberg

4. **Queries AnalÃ­ticas**
   - 8 queries de exemplo demonstrando anÃ¡lises de negÃ³cio
   - Time travel e schema evolution

5. **TransformaÃ§Ãµes dbt**
   - Modelos staging (limpeza)
   - Modelos marts (anÃ¡lise)
   - DimensÃµes e fatos

## ğŸŒ Acessando os ServiÃ§os

### MinIO Console

**URL**: http://localhost:9001

**Credenciais**:
- UsuÃ¡rio: `admin`
- Senha: `minioadmin123`

No console vocÃª pode:
- Ver buckets e objetos
- Navegar pela estrutura de arquivos Iceberg
- Ver metadados

### DuckDB (via container)

```bash
# Entrar no container DuckDB
docker compose exec duckdb bash

# Executar Python interativo
python

# Ou executar scripts diretamente
docker compose exec duckdb python /app/scripts/example_queries.py
```

### dbt

```bash
# Entrar no container dbt
docker compose exec dbt bash

# Executar modelos
dbt run

# Executar testes
dbt test

# Gerar documentaÃ§Ã£o
dbt docs generate
dbt docs serve --port 8080
```

## ğŸ’¡ Exemplos de Uso

### 1. Executar Queries de Exemplo

```bash
docker compose exec duckdb python /app/scripts/example_queries.py
```

Isso executarÃ¡ 8 queries demonstrando:
- Receita por categoria
- TendÃªncia de vendas mensal
- Top clientes
- AnÃ¡lise por canal
- Time travel
- Schema evolution
- Performance de produtos
- AnÃ¡lise regional

### 2. Executar TransformaÃ§Ãµes dbt

```bash
# Executar todos os modelos
docker compose exec dbt dbt run

# Executar apenas staging
docker compose exec dbt dbt run --select staging

# Executar apenas marts
docker compose exec dbt dbt run --select marts

# Executar testes
docker compose exec dbt dbt test
```

### 3. Query Direta no DuckDB

```bash
docker compose exec duckdb python
```

```python
import duckdb
import os

# Conectar
con = duckdb.connect()

# Configurar S3
con.execute("""
    INSTALL httpfs;
    LOAD httpfs;
    SET s3_endpoint='minio:9000';
    SET s3_access_key_id='admin';
    SET s3_secret_access_key='minioadmin123';
    SET s3_use_ssl=false;
    SET s3_url_style='path';
""")

# Query
result = con.execute("""
    SELECT 
        categoria,
        COUNT(*) as total,
        SUM(valor_final) as receita
    FROM vendas_iceberg
    GROUP BY categoria
    ORDER BY receita DESC;
""").fetchdf()

print(result)
```

### 4. Adicionar Mais Dados

```bash
# Gerar mais dados
docker compose exec duckdb python /app/scripts/generate_fake_data.py

# Inserir na tabela Iceberg
docker compose exec duckdb python -c "
import sys
sys.path.append('/app/scripts')
from create_iceberg_table import *
con = duckdb.connect()
setup_s3_connection(con)
insert_data_from_parquet(con, '/app/data/vendas_raw.parquet')
"
```

### 5. Explorar Metadados Iceberg

```bash
# Listar snapshots (via MinIO Console ou cÃ³digo)
docker compose exec duckdb python -c "
import duckdb
con = duckdb.connect()
# Configurar S3...
# Consultar metadados Iceberg
"
```

## ğŸ”„ ComparaÃ§Ã£o com Databricks

Este projeto simula uma arquitetura similar ao **Databricks Lakehouse**:

| Recurso | Databricks | Este Projeto |
|---------|-----------|--------------|
| **Storage** | DBFS / S3 / ADLS | MinIO (S3-compatible) |
| **Table Format** | Delta Lake | Apache Iceberg |
| **Query Engine** | Spark SQL | DuckDB |
| **Transform** | dbt / Spark | dbt |
| **Time Travel** | âœ… Sim | âœ… Sim (Iceberg) |
| **Schema Evolution** | âœ… Sim | âœ… Sim (Iceberg) |
| **ACID** | âœ… Sim | âœ… Sim (Iceberg) |
| **UI** | Databricks Notebooks | Docker CLI / MinIO Console |

### Vantagens deste Projeto

- âœ… **100% Local**: Roda completamente offline
- âœ… **Zero Custo**: Sem necessidade de cloud
- âœ… **Educacional**: Ideal para aprender conceitos
- âœ… **RÃ¡pido Setup**: `docker compose up` e pronto
- âœ… **Open Source**: Todas as tecnologias sÃ£o open source

### LimitaÃ§Ãµes vs Databricks

- âš ï¸ **Escala**: Limitado a mÃ¡quina local (vs cluster distribuÃ­do)
- âš ï¸ **ColaboraÃ§Ã£o**: Sem notebooks compartilhados
- âš ï¸ **ML**: Sem MLflow integrado
- âš ï¸ **GovernanÃ§a**: Sem Unity Catalog
- âš ï¸ **Performance**: DuckDB Ã© single-node (vs Spark distribuÃ­do)

## ğŸ› ï¸ Troubleshooting

### MinIO nÃ£o inicia

```bash
# Verificar logs
docker compose logs minio

# Reiniciar serviÃ§o
docker compose restart minio
```

### Tabela Iceberg nÃ£o encontrada

```bash
# Re-executar inicializaÃ§Ã£o
docker compose up init
```

### Erro de conexÃ£o S3

Verifique as variÃ¡veis de ambiente no `docker-compose.yml` e certifique-se de que o MinIO estÃ¡ rodando.

### dbt nÃ£o encontra tabela

Certifique-se de que a tabela Iceberg foi criada primeiro:
```bash
docker compose exec duckdb python /app/scripts/create_iceberg_table.py
```

## ğŸ“ PrÃ³ximos Passos

Ideias para expandir o projeto:

- [ ] Adicionar mais tabelas (clientes, produtos separados)
- [ ] Implementar streaming de dados
- [ ] Adicionar testes automatizados
- [ ] Criar dashboards (Grafana/Metabase)
- [ ] Implementar CI/CD
- [ ] Adicionar Airflow para orquestraÃ§Ã£o
- [ ] Implementar data quality checks

## ğŸ“„ LicenÃ§a

Este projeto Ã© open source e estÃ¡ disponÃ­vel para fins educacionais.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

## ğŸ“š ReferÃªncias

- [Apache Iceberg](https://iceberg.apache.org/)
- [DuckDB](https://duckdb.org/)
- [MinIO](https://min.io/)
- [dbt](https://www.getdbt.com/)
- [Databricks Lakehouse](https://www.databricks.com/product/data-lakehouse)

---

**Desenvolvido com â¤ï¸ para aprendizado de engenharia de dados modernos**
